qplot(f[,8:19],aes(f[,8],f[,9]), geom="boxplot")
plot(f[,8],f[,9])
plot(f[,8],f[,9],col=f$Please.indicate.your.geneder)
boxplot(f[,8:19],  names=c(8:19),pars=list(ylim=c(1,10)), col=colors)
boxplot(f[,8:19],  names=c(8:19),pars=list(ylim=c(1,10)), col=8:19)
jpeg("boxplot.jpeg")
boxplot(f[,8:19],  names=c(8:19),pars=list(ylim=c(1,10)), col=8:19)
dev.off()
mean(f[,8:19])
table.freq(f)
apply(f[,8:19], 2 mean)
apply(f[,8:19], 2, mean)
plot(apply(f[,8:19], 2, mean))
qplot(f[,3]~f[,8], geom="boxplot")
qplot(~f[,8], geom="boxplot")
qplot(~f[,8], data = f, geom="boxplot")
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot")
qplot(x=f[,3],y=f[,8:9], data = f, geom="boxplot")
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot")
boxplot(f[,8:19],fill=f[,3],  names=c(8:19),pars=list(ylim=c(1,10)), col=8:19)
boxplot(f[,8:19],fill=f[,3],  names=c(8:19),pars=list(ylim=c(1,10)))
boxplot(f[,8:19],fill=f[,3]  names=c(8:19),pars=list(ylim=c(1,10)), col=8:19)
boxplot(f[,8:19],  names=c(8:19),pars=list(ylim=c(1,10)), col=8:19)
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot")
plot(apply(f[,8:19], 2, mean))
hist(apply(f[,8:19], 2, mean))
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot")
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot", fill=f[,3])
jpeg("boxplot_gender_vs._f8.jpeg")
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot", fill=f[,3])
dev.off()
qplot(x=f[,3],y=f[,2], data = f, geom="boxplot", fill=f[,3])
qplot(x=f[,3],y=f[,4], data = f, geom="boxplot", fill=f[,3])
qplot(x=f[,3],y=f[,5], data = f, geom="boxplot", fill=f[,3])
qplot(x=f[,3],y=f[,6], data = f, geom="boxplot", fill=f[,3])
qplot(x=f[,3],y=f[,7], data = f, geom="boxplot", fill=f[,3])
qplot(x=f[,3],y=f[,8], data = f, geom="boxplot", fill=f[,3])
qplot(x=f[,3],y=f[,9], data = f, geom="boxplot", fill=f[,3])
jpeg("boxplot_gender_vs._f9.jpeg")
qplot(x=f[,3],y=f[,9], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f10.jpeg")
qplot(x=f[,3],y=f[,10], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f11.jpeg")
qplot(x=f[,3],y=f[,11], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f12.jpeg")
qplot(x=f[,3],y=f[,12], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f13.jpeg")
qplot(x=f[,3],y=f[,13], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f14.jpeg")
qplot(x=f[,3],y=f[,14], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f15.jpeg")
qplot(x=f[,3],y=f[,15], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f16.jpeg")
qplot(x=f[,3],y=f[,16], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f17.jpeg")
qplot(x=f[,3],y=f[,17], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f18.jpeg")
qplot(x=f[,3],y=f[,18], data = f, geom="boxplot", fill=f[,3])
dev.off()
jpeg("boxplot_gender_vs._f19.jpeg")
qplot(x=f[,3],y=f[,19], data = f, geom="boxplot", fill=f[,3])
dev.off()
plot(f[,8],f[,9],col=f$Please.indicate.your.geneder)
hist(apply(f[,8:19], 2, mean))
hist(apply(f[,8:19], 2, mean), xlim=c(1,10))
apply(f[,8:19], 2, mean)
m = apply(f[,8:19], 2, mean)
length(m)
m
names(m)=null
names(m)=NULL
m
plot(apply(f[,8:19], 2, mean), xlim=c(1,10))
plot(apply(f[,8:19], 2, mean)
plot(apply(f[,8:19], 2, mean, type="l")
plot(apply(f[,8:19], 2, mean), type="l")
plot(apply(f[,8:19], 2, mean), type="b")
plot(apply(f[,8:19], 2, mean), type="c")
plot(apply(f[,8:19], 2, mean), type="h")
plot(apply(f[,8:19], 2, mean), type="s")
plot(apply(f[,8:19], 2, mean), type="h")
plot(apply(f[,8:19], 2, mean), type=c("h","c"))
plot(apply(f[,8:19], 2, mean), type="h")
plot(apply(f[,8:19], 2, mean), type="b")
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10))
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10), xlim=c(8:19))
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10), xlim=c(8,19))
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10), names=c(8,19))
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10)
jpeg("means.jpeg")
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10)
dev.off()
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10))
dev.off()
jpeg("means.jpeg")
plot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10))
dev.off()
plotmeans(f[,3],f[,8])
plotmeans(f[,3]~f[,8])
library(gplots)
install.packages("gplots")
library(gplots)
plotmeans(f[,3]~f[,8])
barplot(apply(f[,8:19], 2, mean), type="b", ylim=c(1,10))
barplot(apply(f[,8:19], 2, mean), )
barplot(apply(f[,8:19], 2, mean), col=1:12 )
barplot(apply(f[,8:19], 2, mean), col=1:12 , xlab="asd")
barplot(apply(f[,8:19], 2, mean))
jpeg("means2.jpeg")
barplot(apply(f[,8:19], 2, mean))
dev.off()
barplot(apply(f[,8:19], 2, sd))
jpeg("means2.jpeg")
jpeg("standard_deviation.jpeg")
barplot(apply(f[,8:19], 2, sd))
dev.off()
barplot(f[,8],f[,9])
barplot(apply(f[,8:19], 2, mean))
dev.off()
dev.off()
jpeg("means2.jpeg")
barplot(apply(f[,8:19], 2, mean))
dev.off()
library(corrplot)
install.packages("corrplot")
corr = cor(scale(f[,8:19], center=T, scale=T))
corrplot(corr, order="hclust")
library(corrplot)
corrplot(corr, order="hclust")
corrplot(corr, method="circle")
jpeg("corr.jpeg")
corrplot(corr, method="circle")
dev.off()
names(f)=NULL
corr = cor(scale(f[,8:19], center=T, scale=T))
corrplot(corr, method="circle")
corrplot.mixed(corr)
jpeg("corr.jpeg")
corrplot.mixed(corr)
dev.off()
qt(0.975,9)
qt(0.975,8)
help(qt)
qt(0.975,16)
qt(0.975,18)
9*0.6^2+9*0.68^2
sqrt((9*0.6^2+9*0.68^2)/18)
sqrt((9*0.6^2+9*0.68^2)/18)/sqrt(5)
sqrt((9*0.6^2+9*0.68^2)/18)/sqrt(5)*2.1
sqrt((9*(0.6^2)+9*0.68^2)/18)/sqrt(5)*2.1
qt(0.9, 20)
qt(0.95, 20)
qt(0.05, 20)
qt(0.975,18.66)
qt(0.95,15.5)
qt(0.975,8)
6/qt(0.975,8)*sqrt(2)
6/qt(0.975,16)*sqrt(2)
6/qt(0.975,16)
6/qt(0.975,8)
(9*0.6+9*0.68)/18
sqrt((9*0.6+9*0.68)/18)
-2+2.1*0.8/sqrt(5)
-2-2.1*0.8/sqrt(5)
qt(0.95,10)
qt(0.9,10)
(0.5^2)
(sqrt(0.5^2/100+4/100))/((0.5^2/100)^2/99 + (4/100)^2/99)
((0.5^2/100+4/100)^2)/((0.5^2/100)^2/99 + (4/100)^2/99)
qt(0.975, ((0.5^2/100+4/100)^2)/((0.5^2/100)^2/99 + (4/100)^2/99))
-2+qt(0.975, ((0.5^2/100+4/100)^2)/((0.5^2/100)^2/99 + (4/100)^2/99)) * sqrt(0.5^2/100+4/100)
-2-qt(0.975, ((0.5^2/100+4/100)^2)/((0.5^2/100)^2/99 + (4/100)^2/99)) * sqrt(0.5^2/100+4/100)
4+0.2*1.645
1/20
1/20*1.645
2/1/20
2/0.05
data(mtcars)
load(mtcars)
head(mtcars)
qnorm(0.975,mtcars$mpg)
mean = mean(mtcars$mpg)
sd = sd(mtcars$mpg)
mean+qnorm(0.975,mean = mean, sd = sd)*sd
mean-qnorm(0.975,mean = mean, sd = sd)*sd
qnorm(0.975,mean = mean, sd = sd)
qnorm(1-0.975,mean = mean, sd = sd)
qt(1-0.975,mean = mean, sd = sd)
qnorm(1-0.975,nrow(mtcars$mpg))
nrow(mtcars$mpg)
nrow(mtcars)
qnorm(1-0.975,nrow(mtcars))
qnorm(0.975,nrow(mtcars))
mean+qnorm(0.975,nrow(mtcars))*sd/sqrt(nrow(mtcars))
mean+qt(0.975,nrow(mtcars))*sd/sqrt(nrow(mtcars))
mean-qt(0.975,nrow(mtcars))*sd/sqrt(nrow(mtcars))
qt(0.975,8)
qt(1-0.975,8)
qt(1-0.975,8)/9
qt(0.975,8)/9
qt(0.975,8)/3
head(mtcars)
rexp(40, 0.2)
hist(rexp(40, 0.2))
hist(rexp(40, 0.2))
hist(rexp(40, 0.2))
hist(rexp(40, 0.2))
hist(rexp(40, 0.2))
mns=NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
for (i in 1 : 1000) mns = c(mns, mean(rexp(40)))
hist(mns)
for (i in 1 : 1000) mns = c(mns, mean(rexp(40)))
hist(mns)
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 0.2)))
hist(mns)
mns=NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 0.2)))
hist(mns)
setwd("D:\\DOCS\\Kaggle\\OTTO\\raw_data")
library(caret)
library(foreach)
library(doParallel)
library(h2o)
training = read.csv("train.csv", header = T, na.string=c("","NA"));
testing = read.csv("test.csv", header = T, na.string=c("","NA"));
training = training[,-1]
testing = testing[,-1]
inTrain = createDataPartition(y=training$target, p=0.75, list=FALSE)
cv = training[-inTrain,]
training = training[inTrain,]
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, max_mem_size = '6g',nthreads = 3)
training_h2o <- as.h2o(localH2O, training, key = 'train')
cv_h2o = as.h2o(localH2O, cv, key = 'cv')
model <- h2o.deeplearning(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
activation="TanhWithDropout",
classification = T,
input_dropout_ratio = 0.05, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
#balance_classes = TRUE,
#variable_importance = T,
hidden = c(1024,512,256), # three layers of 50 nodes
epochs = 50) # max. no. of epochs
ptm <- proc.time()
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
confusionMatrix(h2o_prediction$predict, cv$target)
proc.time() - ptm
nlevels(h2o_prediction$predict)
sum(h2o_prediction$predict==cv$target)
(proc.time() - ptm)$elapsed
(proc.time() - ptm)[3]
print(proc.time() - ptm)[3]
system.time(h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o)))
t = system.time(q2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o)))
t
ptm <- Sys.time()
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - ptm
init.time <- Sys.time()
model <- h2o.deeplearning(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o[1:100,], # data in H2O format
activation="TanhWithDropout",
classification = T,
input_dropout_ratio = 0.05, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
#balance_classes = TRUE,
#variable_importance = T,
hidden = c(1024,512,256), # three layers of 50 nodes
epochs = 50) # max. no. of epochs
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - ptm
model@model$params
model@model$params$l1
model@model$params$l2
model@model$params$rho
model@model$params$epsilon
model@model$params$train_samples_per_iteration
model@model$params$max_w2
Sys.time()
init.time <- Sys.time()
Sys.time() - init.time
hist(training_h2o$feat_1)
Sys.time() - init.time
Sys.time() - init.time
hist(training_h2o$feat_1)
Sys.time() - init.time
hist(training_h2o$feat_1+(3/8))
hist(sqrt(training_h2o$feat_1+(3/8)))
hist(sqrt(training_h2o$feat_2+(3/8)))
hist(sqrt(training_h2o$feat_3+(3/8)))
hist(sqrt(training_h2o$feat_4+(3/8)))
hist(sqrt(training_h2o$feat_5+(3/8)))
Sys.time() - init.time
hist(sqrt(training_h2o$feat_55+(3/8)))
barhist(sqrt(training_h2o$feat_55+(3/8)))
barplo(tsqrt(training_h2o$feat_55+(3/8)))
barplot(tsqrt(training_h2o$feat_55+(3/8)))
barplot(sqrt(training_h2o$feat_55+(3/8)))
barplot(training_h2o$feat_55)
barplot(as.vector(training_h2o$feat_55))
barplot(as.vector(training$feat_55))
barplot(as.vector(training$feat_55[1:10]))
barplot(as.vector(training$feat_55[1:100]))
barplot(as.vector(training$feat_56[1:100]))
barplot(as.vector(training$feat_57[1:100]))
barplot(as.vector(training$feat_57))
barplot(as.vector(training$feat_56))
barplot(as.vector(training$feat_55))
hist(training$feat_55)
hist(training$feat_55,freq = T)
hist(training$feat_55,breaks=50)
hist(training$feat_55,breaks=500)
hist(training$feat_55,breaks=100)
feat_55 = training$feat_55
nearZeroVar(feat_55)
nearZeroVar(feat_55,saveMetrics = T)
str(feat_55)
summary(feat_55)
summary(scale(feat_55))
mean(feat_55)
max(feat_55)
feat_55.norm = (feat_55-mean(feat_55))/(max(feat_55)-min(feat_55))
summary((feat_55.norm))
barplot(feat_55.norm)
barplot(feat_55)
barplot(feat_55.norm)
hist(feat_55.norm)#,breaks=100)
hist(feat_55.norm,breaks=100)
barplot(feat_55.norm)
barplot(feat_55.norm+(3/8))
barplot(sqrt(feat_55.norm+(3/8)))
nearZeroVar(feat_55,saveMetrics = T)
nearZeroVar(feat_55.norm,saveMetrics = T)
barplot((feat_55.norm+(3/8))^2)
barplot((feat_55.norm+(3/8))^3)
barplot((feat_55.norm+(3/8))^1/2)
barplot((feat_55.norm+(3/8))^1/3)
barplot((feat_55.norm+(3/8))^1/4)
barplot((feat_55.norm+(3/8))^1/5)
barplot((feat_55.norm+(3/8))^1/2)
barplot((feat_55+(3/8))^1/2)
training[,features] = (training[,1:(ncol(training)-1)-mean(feat_55))/(max(feat_55)-min(feat_55))
features = c(1:(ncol(training)-1))
training[,features] = sqrt(training[,features] + (3/8))
cv[,features] = sqrt(cv[,features] + (3/8))
training_h2o <- as.h2o(localH2O, training, key = 'train')
cv_h2o = as.h2o(localH2O, cv, key = 'cv')
init.time <- Sys.time()
model <- h2o.deeplearning(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
activation="TanhWithDropout",
classification = T,
input_dropout_ratio = 0.05, # % of inputs dropout
hidden_dropout_ratios = c(0.5,0.5,0.5), # % for nodes dropout
#balance_classes = TRUE,
#variable_importance = T,
l1=1e-5,
l2=1e-5,
hidden = c(1024,512,256), # three layers of 50 nodes
epochs = 50) # max. no. of epochs
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - init.time
training = read.csv("train.csv", header = T, na.string=c("","NA"));
testing = read.csv("test.csv", header = T, na.string=c("","NA"));
training = training[,-1]
testing = testing[,-1]
features = c(1:(ncol(training)-1))
training[,features] = apply(training[,features], 2, function(col) (col-mean(col))/(max(col)-min(col)) )
barplot(training$feat_1)
barplot(training$feat_2)
barplot(training$feat_3)
barplot(training$feat_4)
barplot(training$feat_4,col=training$target)
barplot(training$target)
hist(training$target)
inTrain = createDataPartition(y=training$target, p=0.75, list=FALSE)
cv = training[-inTrain,]
training = training[inTrain,]
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE, max_mem_size = '6g',nthreads = 3)
training_h2o <- as.h2o(localH2O, training, key = 'train')
cv_h2o = as.h2o(localH2O, cv, key = 'cv')
init.time <- Sys.time()
model = h2o.randomForest(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
classification = T,
ntree = 100,
depth = 40,
mtries = 35)
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - init.time
model = h2o.randomForest(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
classification = T,
ntree = 100,
depth = 70,
mtries = 35)
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
confusionMatrix(h2o_prediction$predict, cv$target)
model = h2o.randomForest(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
classification = T,
ntree = 200,
depth = 50,
mtries = 35)
true_Labels = function(probs, labels)
{
rows = dim(probs)[1]
cols = dim(probs)[2]
classes = names(probs)
act_sample = matrix(rep(classes, rows), nrow = rows, byrow = T)
act_labels = matrix(rep(labels, cols), ncol = cols)
act = (act_labels==act_sample)*1
return (act);
}
#Multilog loss function
MultiLogLoss <- function(act, pred)
{
eps = 1e-15;
nr <- nrow(pred)
pred = matrix(sapply( as.matrix(pred), function(x) max(eps,x)), nrow = nr)
pred = matrix(sapply( as.matrix(pred), function(x) min(1-eps,x)), nrow = nr)
ll = sum(act*log(pred) )
ll = ll * -1/(nrow(act))
return(ll);
}
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
h20_prediction_prob = h2o_prediction[,2:ncol(h2o_prediction)]
confusionMatrix(h2o_prediction$predict, cv$target)
actual_labels = true_Labels(predictions_prob, cv$target)
actual_labels = true_Labels(h2o_prediction_prob, cv$target)
h2o_prediction_prob = h2o_prediction[,2:ncol(h2o_prediction)]
actual_labels = true_Labels(h2o_prediction_prob, cv$target)
error = MultiLogLoss(actual_labels, predictions_prob)
error = MultiLogLoss(actual_labels, h2o_prediction_prob)
model = h2o.randomForest(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
classification = T,
ntree = 200,
depth = 50,
mtries = 55)
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
h2o_prediction_prob = h2o_prediction[,2:ncol(h2o_prediction)]
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - init.time
actual_labels = true_Labels(h2o_prediction_prob, cv$target)
error = MultiLogLoss(actual_labels, h2o_prediction_prob)
error
model = h2o.randomForest(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
classification = T,
ntree = 200,
depth = 50,
mtries = 25)
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
h2o_prediction_prob = h2o_prediction[,2:ncol(h2o_prediction)]
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - init.time
actual_labels = true_Labels(h2o_prediction_prob, cv$target)
error = MultiLogLoss(actual_labels, h2o_prediction_prob)
error
training = read.csv("train.csv", header = T, na.string=c("","NA"));
testing = read.csv("test.csv", header = T, na.string=c("","NA"));
training = training[,-1]
testing = testing[,-1]
nzv_features = nearZeroVar(training)
training = training[,-nzv_features]
testing = testing[,-nzv_features]
features = c(1:(ncol(training)-1))
training[,features] = apply(training[,features], 2, function(col) (col-mean(col))/(max(col)-min(col)) )
inTrain = createDataPartition(y=training$target, p=0.75, list=FALSE)
cv = training[-inTrain,]
training = training[inTrain,]
training_h2o <- as.h2o(localH2O, training, key = 'train')
cv_h2o = as.h2o(localH2O, cv, key = 'cv')
init.time <- Sys.time()
model = h2o.randomForest(x = 1:(ncol(training_h2o)-1),  # column numbers for predictors
y = "target",   # column number for label
data = training_h2o, # data in H2O format
classification = T,
ntree = 200,
depth = 50,
mtries = 25)
h2o_prediction <- as.data.frame(h2o.predict(model, cv_h2o))
h2o_prediction_prob = h2o_prediction[,2:ncol(h2o_prediction)]
confusionMatrix(h2o_prediction$predict, cv$target)
Sys.time() - init.time
actual_labels = true_Labels(h2o_prediction_prob, cv$target)
error = MultiLogLoss(actual_labels, h2o_prediction_prob)
error
